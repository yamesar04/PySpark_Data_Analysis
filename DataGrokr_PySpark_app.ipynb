{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataGrokr_PySpark_app.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVYY3cOB5rRz"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark3.1.2/spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "liMPZRYV5u2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf /content/drive/MyDrive/DataGrokr_Project/spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "86u6-vbB6Vwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "ti0J0swk6fOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "import findspark\n",
        "#findspark.init()"
      ],
      "metadata": {
        "id": "Sk5N5fDN8wEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "findspark.init()"
      ],
      "metadata": {
        "id": "kqD-O3lw8zww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "kgwvbrNr-3im",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1756ae82-6e04-4139-e3d3-6e915dd1a66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 33 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 54.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=da709f59642d11ff41c852ca6dc53bf585187e71ab152198dc8d0bfa3c1fa6ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = (SparkSession\n",
        " .builder\n",
        " .appName(\"DataGrokr\")\n",
        " .getOrCreate())"
      ],
      "metadata": {
        "id": "fHrcqyXE-2Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating dataframes with header row values as column names\n",
        "ball_by_ball_temp= spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/drive/MyDrive/DataGrokr_Project/ipl_dataset_2/ipl_ball_by_ball.csv\")\n",
        "matches_temp= spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/drive/MyDrive/DataGrokr_Project/ipl_dataset_2/ipl_matches.csv\")\n",
        "venue_temp= spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/drive/MyDrive/DataGrokr_Project/ipl_dataset_2/ipl_venue.csv\")"
      ],
      "metadata": {
        "id": "e8EfKotqHYGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ipl matches dataframe and table object creation\n",
        "matches_df= matches_temp.selectExpr(\"cast(match_id as int) match_id\",\\\n",
        "                                    \"cast(date as date) date\",\"cast(player_of_match as string)\",\\\n",
        "                                    \"cast(team1 as string) team1\",\\\n",
        "                                    \"cast(team2 as string) team2\",\\\n",
        "                                    \"cast(toss_winner as string) toss_winner\",\\\n",
        "                                    \"cast(toss_decision as string) toss_decision\",\\\n",
        "                                    \"cast(winner as string) winner\",\\\n",
        "                                    \"cast(result as string) result\",\\\n",
        "                                    \"cast(result_margin as int) resultmargin\",\\\n",
        "                                    \"cast(eliminator as string) eliminator\",\\\n",
        "                                    \"cast(method as string) method\",\\\n",
        "                                    \"cast(umpire1 as string) umpire1\",\\\n",
        "                                    \"cast(umpire2 as string) umpire2\",\\\n",
        "                                    \"cast(venue_id as int) venue_id\",\\\n",
        "                                    \n",
        "                                    )\n",
        "matches_df.createOrReplaceTempView(\"matches_table\")"
      ],
      "metadata": {
        "id": "vGD6Fr2CiOba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ball by ball dataframe and table object creation\n",
        "ball_by_ball_df= ball_by_ball_temp.selectExpr(\"cast(inning as int) inning\"\\\n",
        "                            ,\"cast(overs as int) overs\",\"cast(batsman as string) batsman\"\\\n",
        "                            ,\"cast(non_striker as string) non_striker\", \"cast(bowler as string) bowler\"\\\n",
        "                            ,\"cast(batsman_runs as int) batsman_runs\", \"cast(extra_runs as int) extra_runs\"\\\n",
        "                            ,\"cast(total_runs as int) total_runs\", \"cast(non_boundary as int) non_boundary\"\\\n",
        "                            ,\"cast(is_wicket as int) is_wicket\", \"cast(dismissal_kind as string) dismissal_kind\"\\\n",
        "                            ,\"cast(player_dismissed as string) player_dismissed\", \"cast(fielder as string) fielder\"\\\n",
        "                            ,\"cast(extras_type as string) extras_type\", \"cast(batting_team as string) batting_team\"\\\n",
        "                            ,\"cast(bowling_team as string) bowling_team\", \"cast(match_id as int) match_id\")\n",
        "ball_by_ball_df.createOrReplaceTempView(\"ball_by_ball_table\")"
      ],
      "metadata": {
        "id": "s8_2coA9kIFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#IPL Venue dataframe and table object creation\n",
        "venue_df= venue_temp.selectExpr(\"cast(venue_id as int) venue_id\", \\\n",
        "                                \"cast(venue as string) venue\", \"cast(city as string) city\")\n",
        "venue_df.createOrReplaceTempView(\"venue_table\")"
      ],
      "metadata": {
        "id": "-96IsrMgu1s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#three_in_one_df.createOrReplaceTempView('three_in_one_table')\n",
        "spark.catalog.listTables()"
      ],
      "metadata": {
        "id": "ZGOS9AveJRAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a23929a7-b1c6-4304-f275-1c8130972bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Table(name='ball_by_ball_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='matches_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='venue_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Find the top 3 venues which hosted the most number of eliminator matches?\n",
        "query= \"\"\" SELECT venue, COUNT(matches_table.venue_id) as Number_of_matches  FROM venue_table, matches_table WHERE venue_table.venue_id= matches_table.venue_id and matches_table.eliminator != 'N' and venue_table.venue_id IN\n",
        "(SELECT matches_table.venue_id FROM matches_table, venue_table \\\n",
        "GROUP BY matches_table.venue_id ORDER BY COUNT(matches_table.venue_id) DESC LIMIT 1)\n",
        "GROUP BY venue_table.venue\n",
        "\"\"\" #CREATE SEPERATE VIEWS FOR EACH DATAFRAME AND REFRAME QUERY\n",
        "top3venues= spark.sql(query).show()\n",
        "top3venues"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGp7Y5jRJts-",
        "outputId": "91b7c905-faec-4bce-db87-58655e0249f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------------+\n",
            "|               venue|Number_of_matches|\n",
            "+--------------------+-----------------+\n",
            "|M.Chinnaswamy Sta...|                4|\n",
            "+--------------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Return most number of catches taken by a player in IPL history?\n",
        "query= \"SELECT fielder, COUNT(fielder) FROM ball_by_ball_table WHERE dismissal_kind= 'caught' AND is_wicket= 1 GROUP BY fielder ORDER BY COUNT(fielder) DESC\"\n",
        "spark.sql(query).show(n=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzxxPgZePJt6",
        "outputId": "0dd6feb7-4bf8-473e-ce43-e472f34f362e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------+\n",
            "|   fielder|count(fielder)|\n",
            "+----------+--------------+\n",
            "|KD Karthik|           118|\n",
            "+----------+--------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Write a query to return a report for highest wicket taker in matches which were affected by \n",
        "#Duckworth-Lewis’s method (D/L method).\n",
        "query= \"SELECT bowler, COUNT(bowler) FROM matches_table WHERE method= 'D/L' GROUP BY bowler ORDER BY COUNT(bowler) DESC\"\n",
        "spark.sql(query).show(n=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "CGJe6QhKRVuX",
        "outputId": "731d5c10-0b89-4dba-c6db-d94b645bae59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3af83afb7d55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Duckworth-Lewis’s method (D/L method).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"SELECT bowler, COUNT(bowler) FROM matches_table WHERE method= 'D/L' GROUP BY bowler ORDER BY COUNT(bowler) DESC\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \"\"\"\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtableName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.2-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.2-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`bowler`' given input columns: [matches_table.date, matches_table.eliminator, matches_table.match_id, matches_table.method, matches_table.player_of_match, matches_table.result, matches_table.resultmargin, matches_table.team1, matches_table.team2, matches_table.toss_decision, matches_table.toss_winner, matches_table.umpire1, matches_table.umpire2, matches_table.venue_id, matches_table.winner]; line 1 pos 77;\n'Sort ['COUNT('bowler) DESC NULLS LAST], true\n+- 'Aggregate ['bowler], ['bowler, unresolvedalias('COUNT('bowler), None)]\n   +- Filter (method#132 = D/L)\n      +- SubqueryAlias matches_table\n         +- Project [cast(match_id#68 as int) AS match_id#122, cast(date#69 as date) AS date#123, cast(player_of_match#70 as string) AS player_of_match#136, cast(team1#73 as string) AS team1#124, cast(team2#74 as string) AS team2#125, cast(toss_winner#75 as string) AS toss_winner#126, cast(toss_decision#76 as string) AS toss_decision#127, cast(winner#77 as string) AS winner#128, cast(result#78 as string) AS result#129, cast(result_margin#79 as int) AS resultmargin#130, cast(eliminator#80 as string) AS eliminator#131, cast(method#81 as string) AS method#132, cast(umpire1#82 as string) AS umpire1#133, cast(umpire2#83 as string) AS umpire2#134, cast(venue_id#71 as int) AS venue_id#135]\n            +- Relation[match_id#68,date#69,player_of_match#70,venue_id#71,neutral_venue#72,team1#73,team2#74,toss_winner#75,toss_decision#76,winner#77,result#78,result_margin#79,eliminator#80,method#81,umpire1#82,umpire2#83] csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Write a query to return a report for highest extra runs in a venue (stadium, city).\n",
        "query= \"SELECT COUNT(extra_runs),venue_table.venue FROM ball_by_ball_table, venue_table, matches_table WHERE ball_by_ball_table.match_id= matches_table.match_id AND matches_table.venue_id= venue_table.venue_id GROUP BY venue ORDER BY COUNT(extra_runs) DESC LIMIT 1\"\n",
        "spark.sql(query).show(truncate= False)"
      ],
      "metadata": {
        "id": "54IcRWHeSFqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Write a query to return a report for the cricketers with the most number of players of the\n",
        "#match award in neutral venues.\n",
        "query= \"SELECT player_of_match, COUNT(player_of_match) FROM matches_table GROUP BY player_of_match ORDER BY COUNT(player_of_match) DESC\"\n",
        "spark.sql(query).show(n=5)"
      ],
      "metadata": {
        "id": "gsVszfrNnrNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d8e6d51-b5ec-4fc9-b65f-6d2d3b564516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------------------+\n",
            "|player_of_match|count(player_of_match)|\n",
            "+---------------+----------------------+\n",
            "| AB de Villiers|                    23|\n",
            "|       CH Gayle|                    22|\n",
            "|      RG Sharma|                    18|\n",
            "|      DA Warner|                    17|\n",
            "|       MS Dhoni|                    17|\n",
            "+---------------+----------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Write a query to get a list of top 10 players with the highest batting average\n",
        "query= \"\"\"select sevent.Batsman_, sum(sevent.batsman_runs)/count(sevent.player_dismissed) as Average \n",
        "        from\n",
        "            (\n",
        "             (select batsman as Batsman_,batsman_runs,player_dismissed from ball_by_ball_table) \n",
        "                 union all \n",
        "            (select non_striker as Batsman_,batsman_runs,player_dismissed from ball_by_ball_table)\n",
        "            ) sevent\n",
        "            group by sevent.Batsman_ \n",
        "            order by Average desc LIMIT 10 \"\"\"\n",
        "spark.sql(query).show()"
      ],
      "metadata": {
        "id": "EzkPAvB61xZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3644f1f-efb1-48fa-84ed-694de739ceb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------------------+\n",
            "|     Batsman_|           Average|\n",
            "+-------------+------------------+\n",
            "|        A Nel| 4.333333333333333|\n",
            "|  C Ganapathy|               4.0|\n",
            "|BW Hilfenhaus|               4.0|\n",
            "|    AS Joseph| 2.292682926829268|\n",
            "| BE Hendricks|2.2142857142857144|\n",
            "|     RS Sodhi|               2.2|\n",
            "|    VRV Singh|               2.2|\n",
            "|     Umar Gul| 2.161290322580645|\n",
            "|      SB Wagh|               2.0|\n",
            "|NJ Rimmington|               2.0|\n",
            "+-------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8 Write a query to find out who has officiated (as an umpire) the most number of matches in IPL\n",
        "query= \"\"\"SELECT nipl.umpire, COUNT(nipl.umpire) as count FROM\n",
        "                ((SELECT umpire1 as umpire FROM matches_table )\n",
        "                union all\n",
        "                (SELECT umpire2 as umpire FROM matches_table)) nipl\n",
        "                GROUP BY nipl.umpire\n",
        "                ORDER BY COUNT(nipl.umpire) DESC LIMIT 1\"\"\"\n",
        "spark.sql(query).show()"
      ],
      "metadata": {
        "id": "neDUUxn01xlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9. Find venue details of the match where V Kohli scored his highest individual runs in IPL.\n",
        "query= \"\"\"SELECT MAX(ball_by_ball_table.batsman_runs) , venue_table.venue, ball_by_ball_table.batsman \\\n",
        "        FROM ball_by_ball_table, venue_table, matches_table WHERE ball_by_ball_table.batsman= 'V Kohli' \\\n",
        "        and ball_by_ball_table.match_id= matches_table.match_id and matches_table.venue_id= venue_table.venue_id GROUP BY ball_by_ball_table.batsman \"\"\"\n",
        "spark.sql(query).show()\n"
      ],
      "metadata": {
        "id": "1yP0HGlLzaG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mysql.conncector as msql\n",
        "class Database:\n",
        "    def __init__(self):\n",
        "        self.conn= msql.connect(host= \"127.0.0.1\", user= \"root\", password= \"@*Root12345#\", database= \"ipldb\")\n",
        "        self.cur= self.conn.cursor()\n",
        "    def qone(self):\n",
        "        \"\"\" Find the top 3 venues which hosted the most number of eliminator matches?\"\"\"\n",
        "        query= \"SELECT venue, COUNT(venue) FROM ipl_venue, ipl_matches \\\n",
        "                WHERE ipl_venue.venue_id= ipl_matches.venue_id GROUP BY venue ORDER BY COUNT(venue) DESC LIMIT 3 \"\n",
        "        self.cur.execute(query)\n",
        "        return (dict(self.cur.fetchall()))\n",
        "    def qtwo(self):\n",
        "        \"\"\"Return most number of catches taken by a player in IPL history?\"\"\"\n",
        "        query= \"SELECT fielder, COUNT(fielder) FROM ipl_ball_by_ball \\\n",
        "            WHERE dismissal_kind= 'caught' GROUP BY fielder ORDER BY COUNT(fielder) DESC LIMIT 1\"\n",
        "        self.cur.execute(query)\n",
        "        return dict(self.cur.fetchall())\n",
        "    def qthree(self):\n",
        "        \"\"\"Write a query to return a report for highest wicket taker in matches which were affected by\n",
        "            Duckworth-Lewis’s method (D/L method).\"\"\" #ADD is_wicket= 1 in query\n",
        "        query= \"SELECT bowler, COUNT(bowler) FROM ipl_ball_by_ball WHERE method= 'D/L'\\\n",
        "                AND is_wicket = 1 GROUP BY bowler ORDER BY COUNT(bowler) DESC LIMIT 1\"\n",
        "        self.cur.execute(query)\n",
        "        return dict(self.cur.fetchall())\n",
        "    def qfour(self):\n",
        "        \"\"\"Write a query to return a report for highest strike rate by a batsman in non powerplay\n",
        "        overs(7-20 overs)\n",
        "        Note: strike rate = (Total Runs scored/Total balls faced by player) *100, Make sure that balls\n",
        "        faced by players should be legal delivery (not wide balls or no balls)\"\"\"\n",
        "        pass\n",
        "    def qfive(self):\n",
        "        \"\"\" Write a query to return a report for highest extra runs in a venue (stadium, city).\"\"\"\n",
        "        query= \"SELECT COUNT(ipl_ball_by_ball.extra_runs), ipl_venue.venue FROM \\\n",
        "        ipl_ball_by_ball b, ipl_venue v, ipl_matches m WHERE b.match_id= m.match_id AND \\\n",
        "        m.venue_id= v.venue_id  GROUP BY venue ORDER BY COUNT(extra_runs) LIMIT 3\"\n",
        "        self.cur.execute(query)\n",
        "        return dict(self.cur.fetchall())\n",
        "    def qsix(self):\n",
        "        \"\"\" Write a query to return a report for the cricketers with the most number of players of the\n",
        "        match award in neutral venues.\"\"\"\n",
        "        query= \"SELECT player_of_match, COUNT(player_of_match) FROM ipl_matches GROUP BY \\\n",
        "        player_of_match ORDER BY COUNT(player_of_match) DESC LIMIT 1\"\n",
        "        self.cur.execute(query)\n",
        "        return dict(self.cur.fetchll())\n",
        "    def qseven(self):\n",
        "        \"\"\"Write a query to get a list of top 10 players with the highest batting average \"\"\"\n",
        "        query= \"\"\"select sevent.Batsman_, sum(sevent.batsman_runs)/count(sevent.player_dismissed) as Average \n",
        "        from\n",
        "            (\n",
        "             (select batsman as Batsman_,batsman_runs,player_dismissed from ipl_ball_by_ball) \n",
        "                 union all \n",
        "            (select non_striker as Batsman_,batsman_runs,player_dismissed from ipl_ball_by_ball)\n",
        "            ) sevent\n",
        "            group by sevent.Batsman_ \n",
        "            order by Average desc LIMIT 10 \"\"\"\n",
        "        self.cur.execute(query)\n",
        "        return dict(self.cur.fetchall())\n",
        "    def qeight(self):\n",
        "        \"\"\"Write a query to find out who has officiated (as an umpire) the most number of matches in IPL\"\"\"\n",
        "        query= \"\"\"SELECT nipl.umpire, COUNT(nipl.umpire) as count FROM\n",
        "                ((SELECT umpire1 as umpire FROM ipl_matches )\n",
        "                union all\n",
        "                (SELECT umpire2 as umpire FROM ipl_matches)) nipl\n",
        "                GROUP BY nipl.umpire\n",
        "                ORDER BY COUNT(nipl.umpire) DESC LIMIT 2\"\"\"\n",
        "        self.cur.execute(query)\n",
        "        return dict(self.cur.fetchall())\n",
        "    def qnine(self):\n",
        "        \"\"\"9. Find venue details of the match where V Kohli scored his highest individual runs in IPL.\"\"\"\n",
        "        query= \"SELECT MAX(ipl_ball_by_ball.batsman_runs) , ipl_venue.venue, ipl_ball_by_ball.batsman \\\n",
        "        FROM ipl_ball_by_ball, ipl_venue, ipl_matches WHERE batsman= 'V Kohli' \\\n",
        "        and ipl_ball_by_ball.match_id= ipl_matches.match_id and ipl_matches.venue_id= ipl_venue.venue_id GROUP BY ipl_ball_by_ball.match_id \"\n",
        "        self.cur.execute(query)\n",
        "        return dict(self.cur.fetchall())"
      ],
      "metadata": {
        "id": "48flJ9D11Gd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "ed82a2c9-93db-49c7-b2a7-1113ee07f48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6a8ab34e3dc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmysql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconncector\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDatabase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmsql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"127.0.0.1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"root\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"@*Root12345#\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"ipldb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mysql'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BhF4pUhc_PPN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}